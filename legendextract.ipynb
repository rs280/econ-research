{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "44de0e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing all maps for legend extraction...\n",
      "\n",
      "Error processing abilene-reporter-news-apr-29-1946-p-19_map.png: 400 * GenerateContentRequest.model: unexpected model name format\n",
      "\n",
      "Error processing abilene-reporter-news-apr-29-1946-p-19_map.png: 400 * GenerateContentRequest.model: unexpected model name format\n",
      "\n",
      "Error processing appleton-post-crescent-oct-24-1922-p-13_map.png: 400 * GenerateContentRequest.model: unexpected model name format\n",
      "\n",
      "Error processing appleton-post-crescent-oct-24-1922-p-13_map.png: 400 * GenerateContentRequest.model: unexpected model name format\n",
      "\n",
      "Error processing atchison-daily-globe-nov-30-1943-p-4_map.png: 400 * GenerateContentRequest.model: unexpected model name format\n",
      "\n",
      "⊘ No legend found in abilene-reporter-news-apr-29-1946-p-19_map.png\n",
      "⊘ No legend found in appleton-post-crescent-oct-24-1922-p-13_map.png\n",
      "⊘ No legend found in atchison-daily-globe-nov-30-1943-p-4_map.png\n",
      "\n",
      "============================================================\n",
      "LEGEND EXTRACTION SUMMARY\n",
      "============================================================\n",
      "Total maps processed: 3\n",
      "Legends found: 0\n",
      "Legends saved: 0\n",
      "Metadata saved to: /Users/rishabh/dev/econ-research/legends/legends_metadata.json\n",
      "\n",
      "✓ All legend extractions saved to: /Users/rishabh/dev/econ-research/legends\n",
      "Error processing atchison-daily-globe-nov-30-1943-p-4_map.png: 400 * GenerateContentRequest.model: unexpected model name format\n",
      "\n",
      "⊘ No legend found in abilene-reporter-news-apr-29-1946-p-19_map.png\n",
      "⊘ No legend found in appleton-post-crescent-oct-24-1922-p-13_map.png\n",
      "⊘ No legend found in atchison-daily-globe-nov-30-1943-p-4_map.png\n",
      "\n",
      "============================================================\n",
      "LEGEND EXTRACTION SUMMARY\n",
      "============================================================\n",
      "Total maps processed: 3\n",
      "Legends found: 0\n",
      "Legends saved: 0\n",
      "Metadata saved to: /Users/rishabh/dev/econ-research/legends/legends_metadata.json\n",
      "\n",
      "✓ All legend extractions saved to: /Users/rishabh/dev/econ-research/legends\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "# Helper utilities for legend processing\n",
    "\n",
    "def _normalize_bbox(raw_bbox: Optional[object]) -> Optional[Dict[str, int]]:\n",
    "    \"\"\"Normalize various bbox formats into dict with x,y,width,height.\"\"\"\n",
    "    if raw_bbox is None:\n",
    "        return None\n",
    "    if isinstance(raw_bbox, dict):\n",
    "        if {'x', 'y', 'width', 'height'}.issubset(raw_bbox.keys()):\n",
    "            return {\n",
    "                'x': int(raw_bbox['x']),\n",
    "                'y': int(raw_bbox['y']),\n",
    "                'width': int(raw_bbox['width']),\n",
    "                'height': int(raw_bbox['height'])\n",
    "            }\n",
    "        if {'x1', 'y1', 'x2', 'y2'}.issubset(raw_bbox.keys()):\n",
    "            x1, y1 = int(raw_bbox['x1']), int(raw_bbox['y1'])\n",
    "            x2, y2 = int(raw_bbox['x2']), int(raw_bbox['y2'])\n",
    "            return {'x': x1, 'y': y1, 'width': max(0, x2 - x1), 'height': max(0, y2 - y1)}\n",
    "    if isinstance(raw_bbox, (list, tuple)) and len(raw_bbox) == 4:\n",
    "        x, y, w, h = raw_bbox\n",
    "        return {'x': int(x), 'y': int(y), 'width': int(w), 'height': int(h)}\n",
    "    return None\n",
    "\n",
    "def _scale_bbox_to_original(bbox: Dict[str, int], scale_x: float, scale_y: float, orig_w: int, orig_h: int) -> Dict[str, int]:\n",
    "    \"\"\"Scale bbox from resized coords back to original image coords and clamp.\"\"\"\n",
    "    if bbox is None:\n",
    "        return None\n",
    "    x = int(bbox['x'] * scale_x)\n",
    "    y = int(bbox['y'] * scale_y)\n",
    "    w = int(bbox['width'] * scale_x)\n",
    "    h = int(bbox['height'] * scale_y)\n",
    "    x = max(0, min(x, orig_w - 1))\n",
    "    y = max(0, min(y, orig_h - 1))\n",
    "    w = max(1, min(w, orig_w - x))\n",
    "    h = max(1, min(h, orig_h - y))\n",
    "    return {'x': x, 'y': y, 'width': w, 'height': h}\n",
    "\n",
    "\n",
    "def save_legend_extraction_results(\n",
    "    map_files: List[Path],\n",
    "    legends_data: List[Dict],\n",
    "    output_dir: Path,\n",
    "    legends_dir: Path\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Process all maps, extract legends with Gemini, and save results.\n",
    "    Returns summary statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    results_summary = {\n",
    "        'total_processed': 0,\n",
    "        'legends_found': 0,\n",
    "        'legends_saved': 0,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    all_legend_metadata = []\n",
    "    \n",
    "    for map_file, legend_info in zip(map_files, legends_data):\n",
    "        results_summary['total_processed'] += 1\n",
    "        has_legend = legend_info.get('has_legend', legend_info.get('legend_exists', False))\n",
    "        \n",
    "        if not has_legend:\n",
    "            print(f\"⊘ No legend found in {map_file.name}\")\n",
    "            continue\n",
    "        \n",
    "        results_summary['legends_found'] += 1\n",
    "        \n",
    "        try:\n",
    "            # Load original map image\n",
    "            original_img = Image.open(map_file)\n",
    "            original_array = np.array(original_img)\n",
    "            orig_h, orig_w = original_array.shape[:2]\n",
    "            \n",
    "            # Pull scale factors from legend_info\n",
    "            scale_info = legend_info.get('_scale', {})\n",
    "            scale_x = float(scale_info.get('sx', 1.0))\n",
    "            scale_y = float(scale_info.get('sy', 1.0))\n",
    "            orig_w = int(scale_info.get('orig_w', orig_w))\n",
    "            orig_h = int(scale_info.get('orig_h', orig_h))\n",
    "            \n",
    "            # Normalize bbox variants\n",
    "            raw_bbox = (legend_info.get('legend_bbox')\n",
    "                        or legend_info.get('legend_bounding_box')\n",
    "                        or legend_info.get('bounding_box')\n",
    "                        or legend_info.get('bbox'))\n",
    "            bbox = _normalize_bbox(raw_bbox)\n",
    "            if not bbox:\n",
    "                print(f\"✗ Missing bounding box for legend in {map_file.name}; skipping save\")\n",
    "                continue\n",
    "            \n",
    "            # Scale bbox back to original size if we resized for inference\n",
    "            scaled_bbox = _scale_bbox_to_original(bbox, scale_x, scale_y, orig_w, orig_h)\n",
    "            legend_crop = extract_legend_crop_from_bbox(original_array, scaled_bbox)\n",
    "            if legend_crop is None:\n",
    "                print(f\"✗ Invalid bbox for {map_file.name}; skipping save\")\n",
    "                continue\n",
    "            \n",
    "            # Save legend crop\n",
    "            map_stem = map_file.stem.replace('_map', '')\n",
    "            legend_output_path = legends_dir / f\"{map_stem}_legend.png\"\n",
    "            \n",
    "            legend_img = Image.fromarray(legend_crop)\n",
    "            legend_img.save(legend_output_path)\n",
    "            legend_info['legend_bbox'] = scaled_bbox\n",
    "            legend_info['mask_available'] = False  # no SAM refinement per request\n",
    "            legend_info['legend_image'] = legend_output_path.name\n",
    "            all_legend_metadata.append(legend_info)\n",
    "            \n",
    "            results_summary['legends_saved'] += 1\n",
    "            \n",
    "            print(f\"✓ Legend extracted from {map_file.name}\")\n",
    "            print(f\"  Location: {legend_info.get('legend_location', 'unknown')}\")\n",
    "            print(f\"  Items: {len(legend_info.get('legend_items', []))}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing {map_file.name}: {str(e)}\"\n",
    "            results_summary['errors'].append(error_msg)\n",
    "            print(f\"✗ {error_msg}\")\n",
    "    \n",
    "    # Save all metadata to JSON\n",
    "    metadata_output = legends_dir / \"legends_metadata.json\"\n",
    "    with open(metadata_output, 'w') as f:\n",
    "        json.dump(all_legend_metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"LEGEND EXTRACTION SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total maps processed: {results_summary['total_processed']}\")\n",
    "    print(f\"Legends found: {results_summary['legends_found']}\")\n",
    "    print(f\"Legends saved: {results_summary['legends_saved']}\")\n",
    "    print(f\"Metadata saved to: {metadata_output}\")\n",
    "    \n",
    "    if results_summary['errors']:\n",
    "        print(f\"\\nErrors encountered:\")\n",
    "        for err in results_summary['errors']:\n",
    "            print(f\"  - {err}\")\n",
    "    \n",
    "    return results_summary\n",
    "\n",
    "# Process all maps\n",
    "print(\"Processing all maps for legend extraction...\\n\")\n",
    "\n",
    "all_legends_data = []\n",
    "for map_file in map_files:\n",
    "    img, img_arr, sx, sy, orig_size = load_and_preprocess_image(map_file)\n",
    "    legend_data = extract_legend_with_gemini(map_file, img_arr)\n",
    "    legend_data['_scale'] = {\n",
    "        'sx': sx,\n",
    "        'sy': sy,\n",
    "        'orig_w': orig_size[0],\n",
    "        'orig_h': orig_size[1]\n",
    "    }\n",
    "    all_legends_data.append(legend_data)\n",
    "\n",
    "# Save results\n",
    "summary = save_legend_extraction_results(map_files, all_legends_data, output_dir, legends_dir)\n",
    "\n",
    "print(f\"\\n✓ All legend extractions saved to: {legends_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb3e5b0",
   "metadata": {},
   "source": [
    "## Section 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4ef4e6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import base64\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "from dataclasses import dataclass, asdict\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "# Google Gemini API\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import GenerationConfig\n",
    "\n",
    "# SAM2 for segmentation refinement\n",
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa384389",
   "metadata": {},
   "source": [
    "## Section 2: Set Up Gemini 3 Flash API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0686ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Gemini 3.0 Flash configured from apikey.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import GenerationConfig\n",
    "\n",
    "# Load Gemini key from apikey.yaml (yaml-only, no env lookup)\n",
    "yaml_path = Path(\"apikey.yaml\")\n",
    "if not yaml_path.exists():\n",
    "    raise FileNotFoundError(\"apikey.yaml not found; add gemini_key there.\")\n",
    "config_data = yaml.safe_load(open(yaml_path)) or {}\n",
    "gemini_key = config_data.get(\"gemini_key\")\n",
    "if not gemini_key:\n",
    "    raise ValueError(\"gemini_key missing in apikey.yaml\")\n",
    "\n",
    "genai.configure(api_key=gemini_key)\n",
    "\n",
    "# Use Gemini 3.0 Flash (vision)\n",
    "gemini_model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "print(\"✓ Gemini 3.0 Flash configured from apikey.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616b2192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_legend_with_gemini(image_path: Path, image_data: np.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    Use Gemini 3 Flash to extract legend information from map image.\n",
    "    Returns structured legend metadata with bounding box.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        def _infer_bbox_from_location(img: np.ndarray, loc: Optional[str]) -> Optional[Dict[str, int]]:\n",
    "            if loc is None:\n",
    "                return None\n",
    "            h, w = img.shape[:2]\n",
    "            box_w, box_h = int(0.32 * w), int(0.32 * h)\n",
    "            loc = (loc or \"\").lower()\n",
    "            if \"top\" in loc and \"left\" in loc:\n",
    "                x, y = int(0.05 * w), int(0.05 * h)\n",
    "            elif \"top\" in loc and \"right\" in loc:\n",
    "                x, y = max(0, w - box_w - int(0.05 * w)), int(0.05 * h)\n",
    "            elif \"bottom\" in loc and \"left\" in loc:\n",
    "                x, y = int(0.05 * w), max(0, h - box_h - int(0.05 * h))\n",
    "            elif \"bottom\" in loc and \"right\" in loc:\n",
    "                x, y = max(0, w - box_w - int(0.05 * w)), max(0, h - box_h - int(0.05 * h))\n",
    "            elif \"right\" in loc:\n",
    "                x, y = max(0, w - box_w - int(0.05 * w)), int(0.2 * h)\n",
    "            elif \"left\" in loc:\n",
    "                x, y = int(0.05 * w), int(0.2 * h)\n",
    "            elif \"center\" in loc:\n",
    "                x, y = int(0.34 * w), int(0.34 * h)\n",
    "            else:\n",
    "                x, y = max(0, w - box_w - int(0.05 * w)), max(0, h - box_h - int(0.05 * h))\n",
    "            return {\n",
    "                \"x\": int(np.clip(x, 0, w-1)),\n",
    "                \"y\": int(np.clip(y, 0, h-1)),\n",
    "                \"width\": int(min(box_w, w)),\n",
    "                \"height\": int(min(box_h, h))\n",
    "            }\n",
    "\n",
    "        def _normalize_bbox_local(raw_bbox: Optional[object]) -> Optional[Dict[str, int]]:\n",
    "            if raw_bbox is None:\n",
    "                return None\n",
    "            if isinstance(raw_bbox, dict):\n",
    "                if {'x', 'y', 'width', 'height'}.issubset(raw_bbox.keys()):\n",
    "                    return {k: int(raw_bbox[k]) for k in ['x', 'y', 'width', 'height']}\n",
    "                if {'x1', 'y1', 'x2', 'y2'}.issubset(raw_bbox.keys()):\n",
    "                    x1, y1, x2, y2 = [int(raw_bbox[k]) for k in ['x1', 'y1', 'x2', 'y2']]\n",
    "                    return {\"x\": x1, \"y\": y1, \"width\": max(0, x2 - x1), \"height\": max(0, y2 - y1)}\n",
    "            if isinstance(raw_bbox, (list, tuple)) and len(raw_bbox) == 4:\n",
    "                x, y, w_box, h_box = raw_bbox\n",
    "                return {\"x\": int(x), \"y\": int(y), \"width\": int(w_box), \"height\": int(h_box)}\n",
    "            return None\n",
    "\n",
    "        # Prepare image for Gemini\n",
    "        img_pil = Image.fromarray(image_data)\n",
    "\n",
    "        # XML-structured prompt enforcing bbox and JSON-only output\n",
    "        prompt = f\"\"\"\n",
    "<task>Extract the LEGEND/KEY from a historical zoning map image.</task>\n",
    "<requirements>\n",
    "  - Always set <has_legend>true/false</has_legend>\n",
    "  - Always include <legend_bbox> with integer pixel coords relative to THIS image size: {{\"x\": int, \"y\": int, \"width\": int, \"height\": int}}\n",
    "  - Include <legend_location> (top-left | top-right | bottom-left | bottom-right | left | right | center | side)\n",
    "  - Include <legend_items> array with: identifier, symbol_pattern_type, visual_description, meaning\n",
    "  - Include map metadata if visible: map_title, map_location, map_year, confidence_level\n",
    "  - If multiple legends/tables exist, merge into one bbox that covers them\n",
    "</requirements>\n",
    "<instructions>\n",
    "  Identify ANY legend/key/table that explains patterns, letters, zone codes, hatching, dots, or fills. Boxes labeled LEGEND/KEY, tables of zone letters (A,B,C...), pattern explanations, or text summaries of zoning classes all count as legend.\n",
    "</instructions>\n",
    "<output_format>\n",
    "{{\n",
    "  \"has_legend\": boolean,\n",
    "  \"legend_bbox\": {{\"x\": int, \"y\": int, \"width\": int, \"height\": int}},\n",
    "  \"legend_location\": string,\n",
    "  \"legend_items\": [\n",
    "    {{\"identifier\": string, \"symbol_pattern_type\": string, \"visual_description\": string, \"meaning\": string}}\n",
    "  ],\n",
    "  \"map_title\": string,\n",
    "  \"map_location\": string,\n",
    "  \"map_year\": string,\n",
    "  \"confidence_level\": \"high\"|\"medium\"|\"low\"\n",
    "}}\n",
    "</output_format>\n",
    "<return>Return STRICT JSON only. No markdown. Do not omit legend_bbox; if approximate, provide best guess.</return>\n",
    "\"\"\"\n",
    "\n",
    "        response = gemini_model.generate_content(\n",
    "            [prompt, img_pil],\n",
    "            generation_config=GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                temperature=0.2,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        legend_data = json.loads(response.text)\n",
    "        legend_data['source_file'] = image_path.name\n",
    "\n",
    "        # Normalize or infer bbox\n",
    "        raw_bbox = (legend_data.get('legend_bbox')\n",
    "                    or legend_data.get('legend_bounding_box')\n",
    "                    or legend_data.get('bounding_box')\n",
    "                    or legend_data.get('bbox'))\n",
    "        norm_bbox = _normalize_bbox_local(raw_bbox)\n",
    "        if norm_bbox is None and legend_data.get('legend_location'):\n",
    "            norm_bbox = _infer_bbox_from_location(image_data, legend_data.get('legend_location'))\n",
    "        legend_data['legend_bbox'] = norm_bbox\n",
    "        if 'legend_exists' in legend_data:\n",
    "            legend_data['has_legend'] = bool(legend_data['legend_exists'])\n",
    "\n",
    "        return legend_data\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path.name}: {str(e)}\")\n",
    "        return {\n",
    "            'has_legend': False,\n",
    "            'error': str(e),\n",
    "            'source_file': image_path.name\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c715de",
   "metadata": {},
   "source": [
    "## Section 3: Load and Preprocess Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b70ed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup directories\n",
    "project_root = Path(\"/Users/rishabh/dev/econ-research\")\n",
    "output_dir = project_root / \"output\"\n",
    "legends_dir = project_root / \"legends\"\n",
    "legends_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Find all extracted map images\n",
    "map_files = sorted(output_dir.glob(\"*_map.png\"))\n",
    "print(f\"Found {len(map_files)} map images to process:\")\n",
    "for f in map_files:\n",
    "    print(f\"  - {f.name}\")\n",
    "\n",
    "def load_and_preprocess_image(image_path: Path, max_size: int = 1024) -> Tuple[Image.Image, np.ndarray, float, float, Tuple[int, int]]:\n",
    "    \"\"\"\n",
    "    Load image and preprocess for Gemini analysis.\n",
    "    Returns (resized PIL Image, np array, scale_x, scale_y, original_size)\n",
    "    scale_x/scale_y map resized coords -> original coords via division.\n",
    "    \"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    orig_w, orig_h = img.size\n",
    "    scale_x = scale_y = 1.0\n",
    "\n",
    "    # Resize if too large (Gemini has limits)\n",
    "    if max(img.size) > max_size:\n",
    "        ratio = max_size / max(img.size)\n",
    "        new_size = tuple(int(d * ratio) for d in img.size)\n",
    "        img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "        scale_x = orig_w / img.size[0]\n",
    "        scale_y = orig_h / img.size[1]\n",
    "    else:\n",
    "        scale_x = scale_y = 1.0\n",
    "\n",
    "    # Convert to RGB if needed (remove alpha)\n",
    "    if img.mode == 'RGBA':\n",
    "        img = img.convert('RGB')\n",
    "\n",
    "    img_array = np.array(img)\n",
    "    return img, img_array, scale_x, scale_y, (orig_w, orig_h)\n",
    "\n",
    "# Test loading\n",
    "if map_files:\n",
    "    test_img, test_arr, sx, sy, orig = load_and_preprocess_image(map_files[0])\n",
    "    print(f\"\\n✓ Sample image loaded: {test_img.size}, dtype: {test_arr.dtype}, scale: ({sx:.3f}, {sy:.3f}), orig: {orig}\")\n",
    "else:\n",
    "    print(\"\\n⚠ No map images found in output directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c48374",
   "metadata": {},
   "source": [
    "## Section 4: Extract Legend Using Gemini 2.5 Flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3fce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_legend_with_gemini(image_path: Path, image_data: np.ndarray) -> Dict:\n",
    "    \"\"\"\n",
    "    Use Gemini 2.5 Flash to extract legend information from map image.\n",
    "    Returns structured legend metadata with bounding box.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        def _infer_bbox_from_location(img: np.ndarray, loc: Optional[str]) -> Optional[Dict[str, int]]:\n",
    "            if loc is None:\n",
    "                return None\n",
    "            h, w = img.shape[:2]\n",
    "            # Fractions for a reasonable legend box\n",
    "            box_w, box_h = int(0.32 * w), int(0.32 * h)\n",
    "            loc = (loc or \"\").lower()\n",
    "            if \"top\" in loc and \"left\" in loc:\n",
    "                x, y = int(0.05 * w), int(0.05 * h)\n",
    "            elif \"top\" in loc and \"right\" in loc:\n",
    "                x, y = max(0, w - box_w - int(0.05 * w)), int(0.05 * h)\n",
    "            elif \"bottom\" in loc and \"left\" in loc:\n",
    "                x, y = int(0.05 * w), max(0, h - box_h - int(0.05 * h))\n",
    "            elif \"bottom\" in loc and \"right\" in loc:\n",
    "                x, y = max(0, w - box_w - int(0.05 * w)), max(0, h - box_h - int(0.05 * h))\n",
    "            elif \"right\" in loc:\n",
    "                x, y = max(0, w - box_w - int(0.05 * w)), int(0.2 * h)\n",
    "            elif \"left\" in loc:\n",
    "                x, y = int(0.05 * w), int(0.2 * h)\n",
    "            elif \"center\" in loc:\n",
    "                x, y = int(0.34 * w), int(0.34 * h)\n",
    "            else:\n",
    "                # Default to bottom-right quarter as many legends live there\n",
    "                x, y = max(0, w - box_w - int(0.05 * w)), max(0, h - box_h - int(0.05 * h))\n",
    "            return {\n",
    "                \"x\": int(np.clip(x, 0, w-1)),\n",
    "                \"y\": int(np.clip(y, 0, h-1)),\n",
    "                \"width\": int(min(box_w, w)),\n",
    "                \"height\": int(min(box_h, h))\n",
    "            }\n",
    "\n",
    "        def _normalize_bbox_local(raw_bbox: Optional[object]) -> Optional[Dict[str, int]]:\n",
    "            if raw_bbox is None:\n",
    "                return None\n",
    "            if isinstance(raw_bbox, dict):\n",
    "                if {'x', 'y', 'width', 'height'}.issubset(raw_bbox.keys()):\n",
    "                    return {k: int(raw_bbox[k]) for k in ['x', 'y', 'width', 'height']}\n",
    "                if {'x1', 'y1', 'x2', 'y2'}.issubset(raw_bbox.keys()):\n",
    "                    x1, y1, x2, y2 = [int(raw_bbox[k]) for k in ['x1', 'y1', 'x2', 'y2']]\n",
    "                    return {\"x\": x1, \"y\": y1, \"width\": max(0, x2 - x1), \"height\": max(0, y2 - y1)}\n",
    "            if isinstance(raw_bbox, (list, tuple)) and len(raw_bbox) == 4:\n",
    "                x, y, w_box, h_box = raw_bbox\n",
    "                return {\"x\": int(x), \"y\": int(y), \"width\": int(w_box), \"height\": int(h_box)}\n",
    "            return None\n",
    "\n",
    "        # Prepare image for Gemini\n",
    "        img_pil = Image.fromarray(image_data)\n",
    "        \n",
    "        # Strict prompt requiring a bounding box\n",
    "        prompt = \"\"\"You are extracting the LEGEND/KEY from a historical zoning map image. Return STRICT JSON only.\n",
    "\n",
    "REQUIREMENTS:\n",
    "- Always include `has_legend` (bool)\n",
    "- Always include `legend_bbox` with integer pixel coords: {\"x\": int, \"y\": int, \"width\": int, \"height\": int}\n",
    "- Include `legend_location` (top-left | top-right | bottom-left | bottom-right | left | right | center | side)\n",
    "- Include `legend_items` array with {identifier, symbol_pattern_type, visual_description, meaning}\n",
    "- Include map metadata if visible: map_title, map_location, map_year, confidence_level\n",
    "\n",
    "Identify ANY legend/key/box/table that explains patterns, letters, or zone codes. Examples: boxes labeled LEGEND/KEY, tables of zone letters (A,B,C...), pattern explanations (hatching, dots, solid fills), or text summaries of zoning classes.\n",
    "\n",
    "Output JSON schema:\n",
    "{\n",
    "  \"has_legend\": boolean,\n",
    "  \"legend_bbox\": {\"x\": int, \"y\": int, \"width\": int, \"height\": int},\n",
    "  \"legend_location\": string,\n",
    "  \"legend_items\": [\n",
    "    {\"identifier\": string, \"symbol_pattern_type\": string, \"visual_description\": string, \"meaning\": string}\n",
    "  ],\n",
    "  \"map_title\": string,\n",
    "  \"map_location\": string,\n",
    "  \"map_year\": string,\n",
    "  \"confidence_level\": \"high\"|\"medium\"|\"low\"\n",
    "}\n",
    "\n",
    "Return ONLY valid JSON. Do not include markdown or extra text. Do not omit legend_bbox; if approximate, provide best guess.\"\"\"\n",
    "\n",
    "        # Call Gemini with vision\n",
    "        response = gemini_model.generate_content(\n",
    "            [prompt, img_pil],\n",
    "            generation_config=GenerationConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                temperature=0.3,\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        legend_data = json.loads(response.text)\n",
    "        legend_data['source_file'] = image_path.name\n",
    "\n",
    "        # Normalize or infer bbox so downstream saving works\n",
    "        raw_bbox = (legend_data.get('legend_bbox')\n",
    "                    or legend_data.get('legend_bounding_box')\n",
    "                    or legend_data.get('bounding_box')\n",
    "                    or legend_data.get('bbox'))\n",
    "        norm_bbox = _normalize_bbox_local(raw_bbox)\n",
    "        if norm_bbox is None and legend_data.get('legend_location'):\n",
    "            norm_bbox = _infer_bbox_from_location(image_data, legend_data.get('legend_location'))\n",
    "        legend_data['legend_bbox'] = norm_bbox\n",
    "        # Ensure has_legend mirrors legend_exists if provided\n",
    "        if 'legend_exists' in legend_data:\n",
    "            legend_data['has_legend'] = bool(legend_data['legend_exists'])\n",
    "        \n",
    "        return legend_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path.name}: {str(e)}\")\n",
    "        return {\n",
    "            'has_legend': False,\n",
    "            'error': str(e),\n",
    "            'source_file': image_path.name\n",
    "        }\n",
    "\n",
    "# Test on first map\n",
    "if map_files:\n",
    "    print(\"Extracting legend from first map with Gemini 2.5 Flash...\")\n",
    "    print(f\"Processing: {map_files[0].name}\\n\")\n",
    "    \n",
    "    img, img_arr = load_and_preprocess_image(map_files[0])\n",
    "    legend_result = extract_legend_with_gemini(map_files[0], img_arr)\n",
    "    \n",
    "    print(\"Legend Extraction Result:\")\n",
    "    print(json.dumps(legend_result, indent=2))\n",
    "else:\n",
    "    print(\"⚠ No maps to process\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072ffa35",
   "metadata": {},
   "source": [
    "## Section 5: Prepare Data for SAM Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d702cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_legend_crop_from_bbox(image: np.ndarray, bbox: Dict) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Extract legend region from image using bounding box from Gemini.\n",
    "    bbox should have: x, y, width, height\n",
    "    \"\"\"\n",
    "    try:\n",
    "        h, w = image.shape[:2]\n",
    "        x = int(bbox.get('x', 0))\n",
    "        y = int(bbox.get('y', 0))\n",
    "        width = int(bbox.get('width', w))\n",
    "        height = int(bbox.get('height', h))\n",
    "        \n",
    "        # Validate bounds\n",
    "        x = max(0, min(x, w))\n",
    "        y = max(0, min(y, h))\n",
    "        x2 = min(w, x + width)\n",
    "        y2 = min(h, y + height)\n",
    "        \n",
    "        if x2 <= x or y2 <= y:\n",
    "            return None\n",
    "        \n",
    "        # Extract crop\n",
    "        crop = image[y:y2, x:x2]\n",
    "        \n",
    "        # Add padding (10% margin)\n",
    "        pad = int(max(crop.shape[0], crop.shape[1]) * 0.05)\n",
    "        pad_top = max(0, y - pad)\n",
    "        pad_left = max(0, x - pad)\n",
    "        pad_bottom = min(h, y2 + pad)\n",
    "        pad_right = min(w, x2 + pad)\n",
    "        \n",
    "        padded_crop = image[pad_top:pad_bottom, pad_left:pad_right]\n",
    "        \n",
    "        return padded_crop\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting crop: {e}\")\n",
    "        return None\n",
    "\n",
    "# Prepare training data for SAM2\n",
    "@dataclass\n",
    "class LegendTrainingData:\n",
    "    image_path: Path\n",
    "    legend_region: np.ndarray\n",
    "    bbox: Tuple[int, int, int, int]  # (x, y, x2, y2)\n",
    "    metadata: Dict\n",
    "    \n",
    "def prepare_sam_training_data(map_files: List[Path], legends_data: List[Dict]) -> List[LegendTrainingData]:\n",
    "    \"\"\"\n",
    "    Prepare training data for SAM2 fine-tuning.\n",
    "    Returns list of LegendTrainingData objects with legend crops and bounding boxes.\n",
    "    \"\"\"\n",
    "    training_data = []\n",
    "    \n",
    "    for map_file, legend_info in zip(map_files, legends_data):\n",
    "        if not legend_info.get('has_legend', False):\n",
    "            continue\n",
    "            \n",
    "        # Load full image\n",
    "        img = Image.open(map_file)\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # Extract legend crop\n",
    "        bbox = legend_info.get('legend_bbox')\n",
    "        if not bbox:\n",
    "            continue\n",
    "            \n",
    "        legend_crop = extract_legend_crop_from_bbox(img_array, bbox)\n",
    "        if legend_crop is None:\n",
    "            continue\n",
    "        \n",
    "        # Calculate precise bounding box in original image\n",
    "        x = int(bbox.get('x', 0))\n",
    "        y = int(bbox.get('y', 0))\n",
    "        x2 = x + int(bbox.get('width', 0))\n",
    "        y2 = y + int(bbox.get('height', 0))\n",
    "        \n",
    "        training_data.append(LegendTrainingData(\n",
    "            image_path=map_file,\n",
    "            legend_region=legend_crop,\n",
    "            bbox=(x, y, x2, y2),\n",
    "            metadata=legend_info\n",
    "        ))\n",
    "    \n",
    "    return training_data\n",
    "\n",
    "print(\"✓ SAM training data preparation functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9b324a",
   "metadata": {},
   "source": [
    "## Section 6: Fine-tune SAM2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8287b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SAM2 model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "checkpoint = \"sam2.1_hiera_base_plus.pt\"\n",
    "model_cfg = \"configs/sam2.1/sam2.1_hiera_b+.yaml\"\n",
    "\n",
    "try:\n",
    "    sam2_model = build_sam2(model_cfg, checkpoint, device=device)\n",
    "    sam_predictor = SAM2ImagePredictor(sam2_model)\n",
    "    print(\"✓ SAM2 model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ Note: SAM2 loading may require specific setup. Error: {e}\")\n",
    "    print(\"Proceeding with legend extraction without SAM2 fine-tuning for now.\")\n",
    "    sam_predictor = None\n",
    "\n",
    "def refine_legend_with_sam2(image: np.ndarray, bbox: Tuple[int, int, int, int]) -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Use SAM2 to refine legend segmentation and create precise mask.\n",
    "    bbox: (x, y, x2, y2)\n",
    "    Returns binary mask of legend region.\n",
    "    \"\"\"\n",
    "    if sam_predictor is None:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Set image for SAM2\n",
    "        sam_predictor.set_image(image)\n",
    "        \n",
    "        # Convert bbox to center point and approximate area\n",
    "        x, y, x2, y2 = bbox\n",
    "        center_x, center_y = (x + x2) // 2, (y + y2) // 2\n",
    "        \n",
    "        # Use point prompt at center of bbox\n",
    "        point_coords = np.array([[center_x, center_y]])\n",
    "        point_labels = np.array([1])  # 1 = foreground\n",
    "        \n",
    "        # Generate mask\n",
    "        masks, scores, logits = sam_predictor.predict(\n",
    "            point_coords=point_coords,\n",
    "            point_labels=point_labels,\n",
    "            multimask_output=False\n",
    "        )\n",
    "        \n",
    "        # Return the mask\n",
    "        return masks[0]  # Binary mask\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"SAM2 refinement error: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"✓ SAM2 refinement functions ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f08f271",
   "metadata": {},
   "source": [
    "## Section 7: Save Extracted Legends to Output Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ef718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_legend_extraction_results(\n",
    "    map_files: List[Path],\n",
    "    legends_data: List[Dict],\n",
    "    output_dir: Path,\n",
    "    legends_dir: Path\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Process all maps, extract legends with Gemini + SAM2, and save results.\n",
    "    Returns summary statistics.\n",
    "    \"\"\"\n",
    "    \n",
    "    results_summary = {\n",
    "        'total_processed': 0,\n",
    "        'legends_found': 0,\n",
    "        'legends_saved': 0,\n",
    "        'errors': []\n",
    "    }\n",
    "    \n",
    "    all_legend_metadata = []\n",
    "    \n",
    "    for map_file, legend_info in zip(map_files, legends_data):\n",
    "        results_summary['total_processed'] += 1\n",
    "        \n",
    "        if not legend_info.get('has_legend', False):\n",
    "            print(f\"⊘ No legend found in {map_file.name}\")\n",
    "            continue\n",
    "        \n",
    "        results_summary['legends_found'] += 1\n",
    "        \n",
    "        try:\n",
    "            # Load original map image\n",
    "            original_img = Image.open(map_file)\n",
    "            original_array = np.array(original_img)\n",
    "            \n",
    "            # Extract legend crop\n",
    "            bbox = legend_info.get('legend_bbox')\n",
    "            if not bbox:\n",
    "                continue\n",
    "            \n",
    "            legend_crop = extract_legend_crop_from_bbox(original_array, bbox)\n",
    "            if legend_crop is None:\n",
    "                continue\n",
    "            \n",
    "            # Save legend crop\n",
    "            map_stem = map_file.stem.replace('_map', '')\n",
    "            legend_output_path = legends_dir / f\"{map_stem}_legend.png\"\n",
    "            \n",
    "            legend_img = Image.fromarray(legend_crop)\n",
    "            legend_img.save(legend_output_path)\n",
    "            \n",
    "            # Try SAM2 refinement if available\n",
    "            bbox_tuple = (\n",
    "                int(bbox.get('x', 0)),\n",
    "                int(bbox.get('y', 0)),\n",
    "                int(bbox.get('x', 0)) + int(bbox.get('width', 0)),\n",
    "                int(bbox.get('y', 0)) + int(bbox.get('height', 0))\n",
    "            )\n",
    "            \n",
    "            sam_mask = refine_legend_with_sam2(original_array, bbox_tuple)\n",
    "            if sam_mask is not None:\n",
    "                mask_output_path = legends_dir / f\"{map_stem}_legend_mask.png\"\n",
    "                mask_img = Image.fromarray((sam_mask * 255).astype(np.uint8))\n",
    "                mask_img.save(mask_output_path)\n",
    "                legend_info['mask_available'] = True\n",
    "            else:\n",
    "                legend_info['mask_available'] = False\n",
    "            \n",
    "            # Save metadata\n",
    "            legend_info['legend_image'] = legend_output_path.name\n",
    "            all_legend_metadata.append(legend_info)\n",
    "            \n",
    "            results_summary['legends_saved'] += 1\n",
    "            \n",
    "            print(f\"✓ Legend extracted from {map_file.name}\")\n",
    "            print(f\"  Location: {legend_info.get('legend_location', 'unknown')}\")\n",
    "            print(f\"  Items: {len(legend_info.get('legend_items', []))}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error processing {map_file.name}: {str(e)}\"\n",
    "            results_summary['errors'].append(error_msg)\n",
    "            print(f\"✗ {error_msg}\")\n",
    "    \n",
    "    # Save all metadata to JSON\n",
    "    metadata_output = legends_dir / \"legends_metadata.json\"\n",
    "    with open(metadata_output, 'w') as f:\n",
    "        json.dump(all_legend_metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"LEGEND EXTRACTION SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total maps processed: {results_summary['total_processed']}\")\n",
    "    print(f\"Legends found: {results_summary['legends_found']}\")\n",
    "    print(f\"Legends saved: {results_summary['legends_saved']}\")\n",
    "    print(f\"Metadata saved to: {metadata_output}\")\n",
    "    \n",
    "    if results_summary['errors']:\n",
    "        print(f\"\\nErrors encountered:\")\n",
    "        for err in results_summary['errors']:\n",
    "            print(f\"  - {err}\")\n",
    "    \n",
    "    return results_summary\n",
    "\n",
    "# Process all maps\n",
    "print(\"Processing all maps for legend extraction...\\n\")\n",
    "\n",
    "all_legends_data = []\n",
    "for map_file in map_files:\n",
    "    img, img_arr = load_and_preprocess_image(map_file)\n",
    "    legend_data = extract_legend_with_gemini(map_file, img_arr)\n",
    "    all_legends_data.append(legend_data)\n",
    "\n",
    "# Save results\n",
    "summary = save_legend_extraction_results(map_files, all_legends_data, output_dir, legends_dir)\n",
    "\n",
    "print(f\"\\n✓ All legend extractions saved to: {legends_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, display the actual map images to see what we're working with\n",
    "map_files = sorted((project_root / \"output\").glob(\"*_map.png\"))\n",
    "\n",
    "if map_files:\n",
    "    print(f\"Displaying {len(map_files)} extracted maps:\\n\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, min(3, len(map_files)), figsize=(18, 6))\n",
    "    if len(map_files) == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = list(axes) if len(map_files) > 1 else [axes]\n",
    "    \n",
    "    for idx, map_file in enumerate(map_files):\n",
    "        ax = axes[idx] if idx < len(axes) else None\n",
    "        if ax is None:\n",
    "            break\n",
    "            \n",
    "        map_img = Image.open(map_file)\n",
    "        ax.imshow(map_img)\n",
    "        \n",
    "        map_name = map_file.stem.replace('_map', '')\n",
    "        ax.set_title(f\"{map_name}\\n{map_img.size[0]}x{map_img.size[1]}px\", fontsize=10, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(f\"✓ Maps displayed\")\n",
    "\n",
    "# Now display extracted legends\n",
    "legend_files = sorted(legends_dir.glob(\"*_legend.png\"))\n",
    "\n",
    "if legend_files:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Found {len(legend_files)} extracted legends:\\n\")\n",
    "    \n",
    "    # Create grid display\n",
    "    n_cols = min(3, len(legend_files))\n",
    "    n_rows = (len(legend_files) + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 5 * n_rows))\n",
    "    \n",
    "    # Handle single or multiple subplots\n",
    "    if len(legend_files) == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten() if n_rows > 1 else list(axes)\n",
    "    \n",
    "    for idx, legend_file in enumerate(legend_files):\n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Load and display legend\n",
    "        legend_img = Image.open(legend_file)\n",
    "        ax.imshow(legend_img)\n",
    "        \n",
    "        # Extract map name from filename\n",
    "        map_name = legend_file.stem.replace('_legend', '')\n",
    "        ax.set_title(f\"{map_name}\", fontsize=12, fontweight='bold')\n",
    "        ax.axis('off')\n",
    "        \n",
    "        print(f\"✓ {legend_file.name} ({legend_img.size[0]}x{legend_img.size[1]}px)\")\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(legend_files), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(legends_dir / \"legends_overview.png\", dpi=100, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n✓ Overview saved to: {legends_dir / 'legends_overview.png'}\")\n",
    "else:\n",
    "    print(\"\\n⚠ No legend images found in legends directory\")\n",
    "\n",
    "# Display metadata summary\n",
    "metadata_file = legends_dir / \"legends_metadata.json\"\n",
    "if metadata_file.exists():\n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"LEGEND METADATA SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for item in metadata:\n",
    "        source = item.get('source_file', 'Unknown')\n",
    "        has_legend = item.get('has_legend', False)\n",
    "        location = item.get('legend_location', 'unknown')\n",
    "        num_items = len(item.get('legend_items', []))\n",
    "        \n",
    "        print(f\"\\n{source}\")\n",
    "        print(f\"  Has legend: {has_legend}\")\n",
    "        print(f\"  Location: {location}\")\n",
    "        print(f\"  Items: {num_items}\")\n",
    "        \n",
    "        if item.get('legend_items'):\n",
    "            for i, leg_item in enumerate(item['legend_items'][:3], 1):  # Show first 3\n",
    "                meaning = leg_item.get('meaning', 'Unknown')\n",
    "                symbol_type = leg_item.get('symbol_type', 'Unknown')\n",
    "                print(f\"    {i}. {meaning} ({symbol_type})\")\n",
    "            \n",
    "            if len(item['legend_items']) > 3:\n",
    "                print(f\"    ... and {len(item['legend_items']) - 3} more items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f718f6",
   "metadata": {},
   "source": [
    "## Visualize Extracted Legends"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
